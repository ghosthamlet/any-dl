ENHANCEMENT:
============




BUGs:
=====


 - using linkextract on "file:///"-urls does not work.

 - "http://www.ardmediathek.de/das-erste/menschen-bei-maischberger/(...)"
   lÃ¤sst sich mit -i -p mp4
              und anderen Parsern, evbenfalls mit -i
              downloaden. Aber ohne -i nicht!




BETTER STRUCTURE, CLEANER CODE:
===============================


 - URL-analysis in network.ml: wouldn#t it be better in parsers.ml?
 - maybe remove print_string(), because print() does the same now.
 - dump is rather a deparse; dump_data is dump-like or deparse-like too;
   possibly better names should be used here



FEATUREs:
=========

 a bit of priority
 =================

 - subst: with replacement-*pattern* (instead of just a string-template)

 - Array2.colmap / Array2.rowmap  map-functions for Array-data.
   (Should behave non-destructive / functional of course.)

 - Refactoring code, using colmap/rowmap functions

 - tagselect: unparse a table should be possible...

 - tagselect: argpairs: different deparsing scheme also would make sense.
              maybe giving back matrix instead of array/list?

 - tagselect: regexp's for selection-pattern  (extraction-pattern also?)

 - tagselect / csv_save: things like tagselect( ... | argpairs)
                         would make sense to be converted to a table of the form

                           argname_1     argname_2  argname_3 ...
                             argval_1_1  argval_2_1   argval_3_1
                             argval_1_2  argval_2_2   argval_3_2
                             argval_1_3  argval_2_3   argval_3_3
                             argval_1_4  argval_2_4   argval_3_4
                              ...         ...          ...

                            and then saved with csv_save...
                       So, this scheme would make sense.
                       But the scheme in use now also make sense to get a good and fast overview.
                       So, maybe, and option for selecting the deparsing scheme would make sense.


 - iselectmatch with 3 parameters would be good:
     * selection-source
     * selection-match-string
     * default-selection

   At the moment, selection-source and default-selection are both the same!

 - slurping the URL-list from the command line, getting it into TMPVAR.
   Must be clear, that the URL-list then is shortened, or that an exception
   for ending any-dl after the parser has finished is called.
   (exc. caught and normal exit)

 - converting HTML to named variables (like it also was planned for XML)
   This would make it easier to select certain data from a docoment / doclist.
   (DOM-to-string as varnames)

 - tagselect: allow Doclist argument as tmpvar to work on

 - DropCol / DropRow also for other data-structures, like Doc_array, Url_list and so on.

 - Special variable for the  tmpvar? maybe $TMPVAR ? || First exploration: there seems to be a problem with internally called Subst (?)
                                                        Must Clean Code there!

 - JSON-parser implementing or using lib for it.
   Some videofile-meta-data is saved in json-format,
   so adding it would make sense.
   Very likely that access will be easier than with simple regexp-matching.

 - JSON-files for saving data with some structure?

 - possibly an option/pragma, that allows parsers to be *not* invoked
   via "-a" CLI switch, because some parsers download anything, not
   a certain video-file (because they are more general, like general
   parsers that download all pics or so.)

 - * new built-in needed:  storematch("MyName"); # stores match.-array under   MyName.(col).(row)
   * new command: astore("NAME");  (autostore() -> store current value like matrix -> NAME.(x).(y) or something like that
   * syntacttic sugar: access to Array.items via  Dot-notation... eg.  $STACK.0, $STACK.1, $STACK.2 and so on.




 lesser Priority
 ===============

 - javascript engine

 - Logfile for sucessful and failed downloads

 - more sophisticated selection menue? (enhancing, what iselectmatch offers).
   (Should be text-only interface, and even ncurses will be overhead. KISS)

 - !!!! XML-deparse -> get values from XML via name :-)

 - matches and assignments -> each match-group one varname... like   (url,vidname,foobar) = match("^(.*)xyz(lala).*?(foobar)")

 - maybe add a more sophisticated program invocation (fork/exec or popen) ?

 - possibly a true stack ( push, pop, dup, exch, ...) might make sense,
   enhancing the one-val-stack concept.

 - would it make sense to allow get also to read the streams?
   Or should there be some other special commadn for it?
   like "get_stream"?
   (but how to achieve this? by using fork/exec to the tools used via system() at the moment?
   Or using stream-reading libraries for this? Are there any such libs and/or OCaml bindings?)

 - if/then/else?  try/catch?

 - possibly switch to ulex instead of ocamllex:
     http://alain.frisch.fr/soft.html#ulex
     http://caml.inria.fr/pub/ml-archives/caml-list/2006/04/6d31ef03a5a1f9a182a9ed2422d266a4.en.html
    ... but ocamlnet uses ulex internally? I could just use ocamlnet for reading/parsing files maybe?

 - Testsuite would help a lot (example where helpful: linkextract problem in  commit c7f3c1ec98d9c3e88d47c93637a50879c0711d05 )
     - tesing sites as well as testing parsers would be needed.





QUESTIONS:
==========

 - how detailed/verbose or how non-verbose should the commands be?
   e.g.  should print; print onl ythe url or url and referrer?
   Should there be more specific commands?
   Or should print get parameters?
   Or should there be something like
      print with referrer;

 - the interactive loop for menue-item selection catches failing int_of_string: default-pattern is used.
   It could also ask again for correct selection.

